# Room Memory System

The PingPong room memory system is now **fully implemented and operational**. This document describes the system capabilities, configuration, and usage.

## Features

### 1. Manual Memory Recording
Agents can manually record important information during conversations:
- **Decisions**: Key decisions made by the group
- **Insights**: Important observations or learnings
- **Questions**: Unresolved questions that need answers
- **Action Items**: Tasks or actions that need to be done

### 2. Automatic Memory Extraction
The system automatically extracts memories from conversations using a local LLM (Ollama):
- Analyzes conversations every 10 messages
- Uses AI to identify important information
- Categorizes extracted content by type (decision, insight, question, action_item)
- Assigns confidence scores and priority levels
- Tags memories for easy retrieval

### 3. Memory Persistence
All memories are stored in SQLite for persistence across sessions:
- Query memories by type, status, priority, tags, or content
- Update and manage memory lifecycle (active, archived, resolved)
- Track memory relationships (which messages, which agents)
- Get statistics and analytics on memory usage

### 4. Memory Injection
When agents join a room, they receive recent memories in their WELCOME event, providing immediate context about the conversation history.

## Configuration

### Environment Variables

```bash
# Ollama host (default: http://192.168.1.4:11434)
OLLAMA_HOST=http://your-ollama-host:11434

# Ollama model (default: deepseek-r1:latest)
OLLAMA_MODEL=deepseek-r1:latest

# Database path (default: ./data/pingpong.db)
DB_PATH=./data/pingpong.db
```

### Recommended Models (November 2025)

**Default Model**: `deepseek-r1:latest` (May 2025 release)
- ‚ö° Speed: ~10-11 seconds per extraction
- üéØ Quality: Excellent - 100% type coverage (Decision, Insight, Question, Action Item)
- üìä Tested: 4/4 memory types extracted correctly
- üÜï Latest: Native JSON output and function calling support

#### Alternative Models

**For Maximum Speed** (2.5x faster):
- `qwen2.5:7b` - 4.2 seconds, 3/4 types (misses some insights)
  ```bash
  ollama pull qwen2.5:7b
  export OLLAMA_MODEL=qwen2.5:7b
  ```

**For Specific Use Cases**:
- `qwen3:8b` - Dual-mode reasoning (fast + slow thinking)
- `gemma3:4b` - Multimodal (text + images), 140+ languages
- `ministral:3b` - Ultra-fast (~3-5s), edge deployment

#### How to Change Models

1. **Pull a new model in Ollama**:
   ```bash
   ollama pull deepseek-r1:latest  # Current default (recommended)
   ollama pull qwen2.5:7b          # Faster alternative
   ollama pull qwen3:8b            # Dual-mode reasoning
   ```

2. **Set the environment variable**:
   ```bash
   export OLLAMA_MODEL=qwen2.5:7b
   ```

3. **Or configure in code** (server/room.ts:167):
   ```typescript
   const ollamaModel = process.env['OLLAMA_MODEL'] || 'deepseek-r1:latest';
   ```

### Model Comparison (Benchmark Results)

| Model | Speed | Type Coverage | Quality | Best For |
|-------|-------|--------------|---------|----------|
| deepseek-r1:latest ‚≠ê | 10.6s | 4/4 (100%) | Excellent | Complete extraction |
| qwen2.5:7b | 4.2s | 3/4 (75%) | Good | Speed priority |
| qwen3:8b | ~10-15s | High | Excellent | Complex reasoning |
| gemma3:4b | ~5-10s | Good | Good | Multilingual |
| ministral:3b | ~3-5s | Good | Good | Edge devices |

## Usage

### Manual Memory Recording

Agents send a `RECORD_MEMORY` command:

```typescript
{
  type: 'RECORD_MEMORY',
  agentId: 'agent-1',
  memoryType: 'decision',  // decision | insight | question | action_item
  content: 'We decided to use PostgreSQL for the database',
  context: 'Database selection discussion',  // optional
  priority: 'high',  // low | medium | high | critical
  tags: ['database', 'architecture'],
  timestamp: Date.now()
}
```

### Querying Memories

Agents send a `QUERY_MEMORY` command:

```typescript
{
  type: 'QUERY_MEMORY',
  agentId: 'agent-1',
  memoryType: 'decision',  // optional - filter by type
  status: 'active',  // optional - active | archived | resolved
  priority: 'high',  // optional - filter by priority
  tags: ['database'],  // optional - filter by tags
  search: 'postgres',  // optional - search in content
  limit: 10,
  offset: 0,
  timestamp: Date.now()
}
```

Response:
```typescript
{
  type: 'MEMORY_QUERY_RESULT',
  memories: [...],  // array of memory entries
  total: 5,  // total matching memories
  limit: 10,
  offset: 0
}
```

### Updating Memories

```typescript
{
  type: 'UPDATE_MEMORY',
  agentId: 'agent-1',
  memoryId: 'memory-uuid',
  content: 'Updated content',  // optional
  priority: 'critical',  // optional
  tags: ['updated', 'tags'],  // optional
  timestamp: Date.now()
}
```

### Memory Lifecycle

**Archive a memory**:
```typescript
{
  type: 'ARCHIVE_MEMORY',
  agentId: 'agent-1',
  memoryId: 'memory-uuid',
  timestamp: Date.now()
}
```

**Resolve a memory** (for questions/action items):
```typescript
{
  type: 'RESOLVE_MEMORY',
  agentId: 'agent-1',
  memoryId: 'memory-uuid',
  timestamp: Date.now()
}
```

**Delete a memory**:
```typescript
{
  type: 'DELETE_MEMORY',
  agentId: 'agent-1',
  memoryId: 'memory-uuid',
  timestamp: Date.now()
}
```

## Testing

### Unit Tests (100% passing)
```bash
npm test -- tests/unit/memory-repository.test.ts --run
```

### Integration Tests (100% passing)
```bash
npm test -- tests/integration/room-memory.test.ts --run
```

### End-to-End Test
```bash
npx tsx test-memory-extraction.ts
```

Note: The E2E test requires Ollama to be running and a model to be available.

## Architecture

### Components

1. **MemoryRepository** (`server/memory-repository.ts`)
   - SQLite-based persistent storage
   - CRUD operations for memories
   - Advanced querying and filtering
   - Statistics and analytics

2. **MemoryExtractor** (`server/memory-extractor.ts`)
   - LLM-based automatic memory extraction
   - Connects to Ollama API
   - Parses and validates extracted memories
   - Confidence scoring and filtering

3. **Room** (`server/room.ts`)
   - Integrates memory system into conversation rooms
   - Tracks messages for extraction
   - Triggers automatic extraction every 10 messages
   - Broadcasts memory events to all agents
   - Injects memories on agent join

### Data Flow

```
1. Agents send messages
2. Room tracks messages in buffer (last 20)
3. Every 10 messages ‚Üí trigger automatic extraction
4. MemoryExtractor calls Ollama LLM
5. LLM analyzes conversation and returns memories
6. MemoryExtractor validates and filters (confidence >= 0.7)
7. Room creates memory entries in repository
8. Room broadcasts MEMORY_RECORDED events to all agents
```

## Performance Notes

- **Manual recording**: Instant (~1ms)
- **Querying**: Very fast (~5-10ms for typical queries)
- **Automatic extraction**: Depends on model size
  - Small models (3B params): ~5-10 seconds
  - Medium models (7-8B params): ~15-40 seconds
  - Large models (20B+ params): ~2+ minutes ‚ö†Ô∏è

For production use with automatic extraction, **use a small/fast model** to avoid blocking the conversation flow.

## Status

‚úÖ **COMPLETE** - All features implemented and tested
- Manual memory recording
- Automatic LLM extraction
- Persistent storage (SQLite)
- Advanced querying
- Memory lifecycle management
- Integration tests passing
- Ollama integration working

**Recommendation**: Configure a faster Ollama model (llama3.2:3b or similar) for practical use in production environments.
