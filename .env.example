# PingPong Environment Configuration
# Copy this file to .env and customize for your setup

# Ollama Configuration for Memory Extraction
# ==========================================

# Ollama host URL
# Default: http://192.168.1.4:11434
OLLAMA_HOST=http://192.168.1.4:11434

# Ollama model for memory extraction
# Default: deepseek-r1:latest (recommended for best quality)
#
# Tested models (November 2025):
# - deepseek-r1:latest  (~10s, 100% type coverage) ‚≠ê RECOMMENDED
# - qwen2.5:7b          (~4s, 75% type coverage, 2.5x faster)
# - qwen3:8b            (~10-15s, dual-mode reasoning)
# - gemma3:4b           (~5-10s, multimodal, multilingual)
# - ministral:3b        (~3-5s, ultra-fast, edge deployment)
#
OLLAMA_MODEL=deepseek-r1:latest

# Database Configuration
# ======================

# SQLite database path for persistent storage
# Default: ./data/pingpong.db
DB_PATH=./data/pingpong.db

# Redis Configuration (for multi-server deployments)
# ==================================================

# Redis host for message bus
# REDIS_HOST=localhost

# Redis port
# REDIS_PORT=6379

# Server Configuration
# ====================

# WebSocket server port
# PORT=8080

# Example: Switch to fast model
# -----------------------------
# Uncomment to use Qwen2.5 for 2.5x faster extraction (with slightly reduced quality)
# OLLAMA_MODEL=qwen2.5:7b

# Example: Use dual-mode reasoning
# ---------------------------------
# Uncomment to use Qwen3 with hybrid fast/slow thinking
# OLLAMA_MODEL=qwen3:8b

# Example: Edge deployment
# ------------------------
# Uncomment for ultra-fast extraction on edge devices
# OLLAMA_MODEL=ministral:3b
